
%%%%%%%%%%%%%%%%%%%%%%% file typeinst.tex %%%%%%%%%%%%%%%%%%%%%%%%%
%
% This is the LaTeX source for the instructions to authors using
% the LaTeX document class 'llncs.cls' for contributions to
% the Lecture Notes in Computer Sciences series.
% http://www.springer.com/lncs       Springer Heidelberg 2006/05/04
%
% It may be used as a template for your own input - copy it
% to a new file with a new name and use it as the basis
% for your article.
%
% NB: the document class 'llncs' has its own and detailed documentation, see
% ftp://ftp.springer.de/data/pubftp/pub/tex/latex/llncs/latex2e/llncsdoc.pdf
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\documentclass[runningheads,a4paper]{llncs}

\usepackage{amssymb}
\setcounter{tocdepth}{3}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{hyperref}

\newcommand{\keywords}[1]{\par\addvspace\baselineskip
\noindent\keywordname\enspace\ignorespaces#1}


\begin{document}

\mainmatter  % start of an individual contribution

% first the title is needed
\title{TELEMETA, Web project for handling academic research sound archives}

% a short form should be given in case it is too long for the running head
\titlerunning{TELEMETA}

% the name(s) of the author(s) follow(s) next
%
% NB: Chinese authors should write their first names(s) in front of
% their surnames. This ensures that the names appear correctly in
% the running heads and the author index.
%
\author{Thomas Fillon\inst{1}
%
\thanks{This work was partially done inside the DIADEMS project funded by the national french agency ANR }%
\and Guillaume Pelerin\inst{1}
 \and Jos{\'e}phine Simonnot\inst{2}
}
%
%\authorrunning{Lecture Notes in Computer Science: Authors' Instructions}
% (feature abused for this document to repeat the title also on left hand pages)

% the affiliations are given next; don't give your e-mail address
% unless you accept that it will be published
\institute{PARISSON, \url{http://www.parisson.com}\\
\url{{thomas.fillon,guillaume.pellerin}@parisson.com}
\and 
CREM, LESC, CNRS UMR 7186, M.A.E. - Universit{\'e} Paris Ouest\\
\url{josephine.simonnot@mae.u-paris10.fr}}

%\toctitle{Lecture Notes in Computer Science}
%\tocauthor{Authors' Instructions}
\maketitle

% Reset Footnote counter after author definition
\setcounter{footnote}{0}


\begin{abstract}
The abstract should summarize the contents of the paper and should
contain at least 70 and at most 150 words. It should be written using the
\emph{abstract} environment.
\keywords{Sound archives, Ethnomusicology, Database, web platform, Metadata}
\end{abstract}


\section{Introduction}

In social sciences like anthropology or linguistic, researchers have to work on multiple type of multimedia documents like photos, videos, sound recordings or databases. The need to easily access, visualize and annotate such materials can be problematic given their diverse formats, sources and given their chronological nature.
This particular concern gets together some laboratories\footnote{the Research Center on Ethnomusicology (CREM), the Musical Acoustics Laboratory (LAM, UMR 7190) and the sound archives of the Mediterranean House of Human Sciences (MMHS)} involved in research on Ethnomusicoly from  the french National Center on Scientific Research (CNRS).

Given those considerations, since 2007, the CREM laboratory and Parisson, a company specialized in the management of audio database, have been developing \emph{Telemeta}, a innovative, collaborative and interdisciplinary web-based multimedia platform that fits the professional requirements from both sound archivists and researchers in ethnomusicology. Since 2008, a first prototype of this platform has been online\footnote{Archives sonores du CNRS, Musée de l'Homme, \url{http://archives.crem-cnrs.fr}}.

%With the help and expertise of Parisson, a company specialized in the management of audio database, a first prototype of this web-based multimedia platform, named \emph{Telemeta} has been online since 2008 and enable to access sound archives of the CREM laboratory and their associated documentations \cite{telemetaCREM}.%\footnote{Archives sonores du CNRS, Musée de l'Homme, \url{http://archives.crem-cnrs.fr}}


%Accessing audio archives materials with numerous collection of items of arbitrary duration ranging from a minute to several hours was a common issue shared by some laboratories from the french National Center on Scientific Research (CNRS) and involved in research on Ethnomusicoly. Those laboratories, the Research Center on Ethnomusicology (CREM),the Musical Acoustics Laboratory (LAM, UMR 7190) and the sound archives of the Mediterranean House of Human Sciences (MMHS) have decided to join together to develop a solution for managing, preserving, accessing and broadcasting their sound archives.


 
\subsection*{Purpose of the demonstration}
The demonstration aims at presenting the features offered by \emph{Telemeta} as detailed in Section~\ref{sec:Telemeta} in the context of ethnomusiclogical sound archives \cite{telemetaCREM}. It focuses on the enhance and collaborative user-experience for accessing the audio items and associated metadata and on the possibility for the expert user to further enrich those metadata.
Another goal of this demonstration is to present the integrated audio analysis tools described in Section~\ref{sec:Timeside}


\section{Telemeta}\label{sec:Telemeta}

Telemeta is a free and open source web audio content management system which introduces useful and secure methods to backup, index, transcode, analyse and publish any digitalized audio file with its metadata. 
An overview of the Telemeta's web interface is illustrated in Figure~\ref{fig:Telemeta}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=12cm]{img/telemeta.png}
  \caption{Screenshot excerpt of the \emph{Telemeta} web interface}\label{fig:Telemeta}
\end{figure}

Telemeta is dedicated to professionals who wants to easily organize, backup, archive and publish documented sound collections of audio files, CDs, digitalized vinyls and magnetic tapes over a strong database, in accordance with open web standards. 

\subsection{Features and Architecture}

\emph{Telemeta} architecture is flexible and can easily be adapted to particular database organization of a given sound archives. The compatibility with other systems is facilitated by the integration of the metadata standards protocols \emph{Dublin Core} and \emph{OAI-PMH} \cite{DublinCore,OAI-PMH}.

%\emph{Telemeta} features multi-criteria text-based search engine and functions to easily navigate inside an audio item.
%+ audio analysis (via TimeSide)
%+ time markers for annotation and segmentation of instant or temporal region of the audio data.

The main features of \emph{Telemeta} are :
\begin{itemize}
\item Web platform :
  \begin{itemize}
  \item \emph{Pure HTML} web user interface including dynamical forms and
    smart workflows
  \item High level \emph{search engine}
  \item \emph{User management} with individual desk, lists, profiles and
    rights
  \item RSS feed generators
  \item XML serialized backup
  \item Strong SQL or Oracle backend
  \item \emph{Multi-language support} (now english and french, german and
    spanish in development)
  \end{itemize}
\item Audio support :
  \begin{itemize}
  \item \emph{Secure archiving, editing and publishing of audio files} over
    internet.
  \item Smart dynamical and skinnable \emph{audio player}
% (thanks to TimeSide  and ​SoundManager2)
  \item \emph{Multi-format support} : FLAC, OGG, MP3, WAV and more
  \item \emph{Playlist management} for all users with CSV data export
  \item "On the fly" \emph{audio analyzing, transcoding and metadata
    embedding} based on an easy plugin architecture
  \end{itemize}
\item Metadata :   
  \begin{itemize}
  \item Social cumulative indexing with \emph{semantic ontologies} and
    \emph{time-coded markers}
  \item \emph{Geo-Navigator} for audio geolocalization
  \item DublinCore compatibility ​and OAI-PMH data provider
  \end{itemize}
\end{itemize}


\subsection{Metadata}\label{sec:metadata}
Beside the audio data, an efficient and dynamic management of the associated metadata is also required. Consulting metadata provide both an exhaustive access to valuable information about the source of the data and to the related work of peer researchers. 
Dynamically handling metadata in a collaborative manner enable to optimize the continuous process of knowledge gathering and enrichment of the materials in the database.  

One of the major challenge is thus the standardization of audio and metadata formats with the aim of long-term preservation and usage of the different materials. 

Metadata provide two different kinds of information about the audio item : contextual information and annotations.
Contextual information consists in :
\begin{itemize}
\item Geographic and cultural information  (Location details, population/social group, ethnographic context)
\item Musical informations (style, composition, interprets, ...)
\item Archiving data (code and reference to the item)
\item Technical data (media type and duration)
\item Related media (any other material (images, video or text document associated with the audio item)
\end{itemize}

Annotation information provides additional comments or analysis done by some expert on the data. Annotations can consist in temporal information such as :
\begin{itemize}
\item segmentation in relevant class or label for ethnomusicological study (e.g. speech versus singing voice segment)
\item time-coded makers for instantaneous comments 
\end{itemize}
It should be notice that those annotations can be done either by an human expert or by some audio processing automatic analysis (see Section~\ref{sec:Timeside}).



\section{TimeSide}\label{sec:Timeside}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=12cm]{img/timeside_schema.pdf}
  \caption{TimeSide architecture}
\end{figure}
\subsection{Audio management}
Gstreamer, web player
with enhance visualization (waveform, spectrogram)
\subsection{Audio features extraction}
Include reference audio feature tools : Aubio + Yaafe + Vamp
\cite{yaafe_ISMIR2010,brossierPhD}
flexible architecture 

\section{Current development and perspectives}
interdisciplinarity is further enhance by the Music Information Retrieval, Speech technology 
Diadems project
\subsection{Audio analysis}
Development of tools  to offer new audio analysis tool to ethnomusicologis research studies 
+ music similarity

\subsection{Automatic segmentation and classification}
\begin{itemize}
\item singing / talking voice segment
\item ...
\end{itemize}


\subsubsection*{Acknowledgments.} 
The authors would like to thanks all the people that have been involved in \emph{Telemeta} specification and development or have provide appreciated thoughts during discussions.



\bibliographystyle{splncs03}
\bibliography{cmmr_2013}


\end{document}
